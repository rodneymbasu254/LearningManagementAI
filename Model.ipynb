{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c742b58a-36cc-4401-b6cc-a524bb12d3da",
   "metadata": {},
   "source": [
    "# The main Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ea73c43-6c92-400d-8b92-5334ed89a1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machine', 'learning', 'is', 'important', 'for', 'ai', 'research']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text\n",
    "\n",
    "# Tokenize text\n",
    "text = \"Machine Learning is important for AI research!\"\n",
    "cleaned_text = clean_text(text)\n",
    "tokens = tokenizer.tokenize(cleaned_text)\n",
    "\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d871d137-1f7e-4cce-b516-300a66e886a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def scrape_wikipedia(topic):\n",
    "    search_url = f\"https://en.wikipedia.org/wiki/{topic.replace(' ', '_')}\"\n",
    "    response = requests.get(search_url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        text = \" \".join([p.text for p in paragraphs[:5]])  # Get first 5 paragraphs\n",
    "        return text\n",
    "    else:\n",
    "        return \"Sorry, I couldn't find relevant study material.\"\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14e17586-009c-48a1-ab3d-d2dca5adf3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Home\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gradio\\analytics.py:106: UserWarning: IMPORTANT: You are using gradio version 4.38.1, however version 4.44.1 is available, please upgrade. \n",
      "--------\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "modelUI = gr.Interface(\n",
    "    fn = scrape_wikipedia,\n",
    "    inputs = 'text',\n",
    "    outputs = gr.Textbox(label = 'The answer to the question requested is')\n",
    ")\n",
    "modelUI.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d09a72cc-3475-4092-9a9f-049d52368d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the topic PlayList\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, I couldn't find relevant study material.\n"
     ]
    }
   ],
   "source": [
    "topic = input(\"Enter the topic\")\n",
    "topic.t\n",
    "study_material = scrape_wikipedia(topic)\n",
    "print(study_material)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a386ae-36b1-406f-89e5-fd75370d7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "engine.say(study_material)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bf8efbc-4387-45c8-8990-4f68e336806c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://cedar.buffalo.edu/~srihari/CSE574/', 'https://online.stanford.edu/courses/xcs229-machine-learning', 'https://ocw.mit.edu/courses/6-036-introduction-to-machine-learning-fall-2020/']\n"
     ]
    }
   ],
   "source": [
    "from serpapi import GoogleSearch\n",
    "\n",
    "def google_search(query):\n",
    "    params = {\n",
    "        \"engine\": \"google\",\n",
    "        \"q\": query + \" site:edu\",\n",
    "        \"api_key\": \"4c3a39f406bb56f40ea28e7b2b59186206d9eb054c352ef8e19552d9900611f2\",\n",
    "    }\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    \n",
    "    links = [result[\"link\"] for result in results[\"organic_results\"][:3]]\n",
    "    return links\n",
    "\n",
    "# Example usage\n",
    "query = \"Machine Learning course material\"\n",
    "search_results = google_search(query)\n",
    "print(search_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a08a92d8-7c32-44ae-a73e-a4f11427a314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Reference textbooks for different parts of the course are \"Pattern Recognition and Machine Learning\" by Chris Bishop (Springer 2006) and  \"Probabilistic Graphical Models\" by Daphne Koller and Nir Friedman (MIT Press 2009) and \"Deep Learning\" by Goodfellow, Bengio and Courville (MIT Press 2016).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "Course topics are listed below with links to lecture slides and lecture videos. \n",
      "\n",
      "\n",
      "\n",
      "The course is followed by two other courses, one focusing on Probabilistic Graphical Models\n",
      "\n",
      "and another on Deep Learning. \n",
      "\n",
      "\n",
      "The slides and videos were last updated in Fall 2020. \n",
      "Chapters 1-17 (Topic titles in Red) are more recently taught versions. \n",
      " \n",
      "\n",
      "The course is followed by two other courses, one focusing on Probabilistic Graphical Models\n",
      "\n",
      "and another on Deep Learning. \n",
      "\n",
      "\n",
      "The slides and videos were last updated in Fall 2020. \n",
      "Chapters 1-17 (Topic titles in Red) are more recently taught versions. \n",
      "\n",
      "\n",
      "This course introduces principles, algorithms, and applications of machine learning from the point of view of modeling and prediction. It includes formulation of learning problems and concepts of representation, over-fitting, and generalization. These concepts are exercised in supervised learning and reinforcement â¦ This course introduces principles, algorithms, and applications of machine learning from the point of view of modeling and prediction. It includes formulation of learning problems and concepts of representation, over-fitting, and generalization. These concepts are exercised in supervised learning and reinforcement learning, with applications to images and to temporal sequences. This course is part of the Open Learning Library, which is free to use.Â You have the option to sign up and enroll in the course if you want to track your progress, or you can view and use all the materials without enrolling.\n"
     ]
    }
   ],
   "source": [
    "def scrape_website(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    text = \" \".join([p.text for p in paragraphs[:5]])\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "for link in search_results:\n",
    "    study_material = scrape_website(link)\n",
    "    print(study_material)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c53347b4-387d-4a62-bb5d-b880f2c66c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load Stanford Q&A dataset\n",
    "squad = load_dataset(\"squad\")\n",
    "\n",
    "\n",
    "print(squad['train'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "308a6692-b612-4b68-987e-97b587f04690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 of 3 \n",
      " \n",
      " \n",
      " \n",
      "SOEN 305 \n",
      "KISII \n",
      "UNIVERSITY \n",
      "UNIVERSITY EXAMINATIONS \n",
      "THIRD YEAR EXAMINATION FOR THE AWARD OF THE  \n",
      "DEGREE OF BACHELOR OF SCIENCE IN SOFTWARE ENGINEERING \n",
      "FIRST SEMESTER, 2023/2024 \n",
      "(AUGUST-DECEMBER, 2023)  \n",
      "SOEN 305: OBJECT ORIENTED PROGRAMMING II [JAVA] \n",
      "STREAM:  Y3 S1  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "TIME:   2 HOURS  \n",
      "DAY: TUESDAY, 03.00–02:00 PM \n",
      " \n",
      " \n",
      "         DATE: 21/11/2023 \n",
      " \n",
      "INSTRUCTIONS  \n",
      "1. Do not write anything on this question paper. \n",
      "2. Answer Question ONE [Compulsory] and any other TWO Questions. \n",
      " \n",
      "QUESTION ONE (30 MARKS) \n",
      "(a) In your words, describe object oriented programming \n",
      " \n",
      " \n",
      " \n",
      "(2 marks) \n",
      "(b) What \n",
      "are \n",
      "abstract \n",
      "methods? \n",
      "Describe \n",
      "the \n",
      "circumstances \n",
      "in \n",
      "which \n",
      "an \n",
      "abstract \n",
      "method would be appropriate  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(2 marks) \n",
      "(c)  \n",
      "i. Create a class called invoice that a hardware store might use to represent an \n",
      "invoice for an item sold at the store. An invoice should include 4 pieces of \n",
      "information as instance variables; a part number (type string), a part description \n",
      "(type string), a quantity of the item being purchased (type int) and a price per item(double). \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(5 marks) \n",
      "ii. . Your class should have a constructor that initializes the 4 instance variables. \n",
      "Provide a set and a get method for each of the 4 instance variables. In addition \n",
      "provide a method named getInvoiceAmount that calculates the invoice amount i.e. multiplies \n",
      "the quantity by the price per item, then returns the amount as a double value. If the quantity is \n",
      "not positive, it should be set to 0.0. (5 marks) \n",
      "iii. Write a test application named invoiceTest that demonstrates class invoice’s \n",
      "capabilities. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(5 marks) \n",
      " \n",
      "Page 2 of 3 \n",
      " \n",
      " \n",
      "(d) Explain how: \n",
      "i. The super reference is important to a child class.  \n",
      " \n",
      " \n",
      "(2 marks) \n",
      "ii. Inheritance support polymorphism \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(2 marks) \n",
      "(e) Describe the principles of the object oriented paradigm \n",
      " \n",
      " \n",
      " \n",
      "(7 marks) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "QUESTION TWO (20 marks) \n",
      "(a) As a software developer, discuss briefly the various error and exception handling options available \n",
      "in Java. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(6 marks) \n",
      "(b) Write a complete java/C++ program that prompt the \n",
      "user to enter two non-negative integer number. Your \n",
      "program should handle bad input data through the use \n",
      "of a try/catch block to handle the \n",
      "inputMismathException \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(8 marks) \n",
      "(c) Explain the difference between implementing an \n",
      "interface and a derived class. Give code illustrations.\n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(6 marks) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "QUESTION THREE (20 marks) \n",
      "(a) Consider a SurveyTaker class, which can be used to \n",
      "collect data from a yes/no survey.  \n",
      "i.  In the class definition, clearly identify one of each \n",
      "of the following components:  field, constructor, method, parameter (4 marks) \n",
      "ii. What would happen if the user called the enterResponse method with an input value other \n",
      "than \"yes\" or \"no\"? For example, suppose the user entered \"maybe\" in the input box when \n",
      "prompted. Would an error occur? If not, what would the method do? Explain your answer. \n",
      "  \n",
      " \n",
      " \n",
      " \n",
      "(5 marks) \n",
      "iii. Discuss the context of use of this keyword in this code. \n",
      " \n",
      " \n",
      "(3 marks) \n",
      "iv. Write an application to test the capability of the SurveyTaker class.  \n",
      " (8 marks) \n",
      " \n",
      "(b) Discuss the concept of method overloading and method overriding as used in object oriented \n",
      "programming. Write simple java codes that illustrates the concepts.  \n",
      " \n",
      "(8 marks) \n",
      " \n",
      "QUESTION FOUR (20 marks) \n",
      "public class SurveyTaker {   \n",
      "private int numOfYes;  \n",
      "private int numOfNo;  \n",
      "public SurveyTaker() {  \n",
      "this.numOfYes = 0;  \n",
      "this.numOfNo = 0;  \n",
      "}  \n",
      "public void enterResponse(String response) {  \n",
      "if (response.equals(\"yes\")) { \n",
      "this.numOfYes++;  \n",
      "} else if (response.equals(\"no\")) { \n",
      "this.numOfNo++;  \n",
      "} }  \n",
      "public int getYesses() {  \n",
      "return this.numOfYes;  \n",
      "}  \n",
      "} \n",
      "Page 3 of 3 \n",
      " \n",
      "(a) Write a program to generate the Graphical User Interface(GUI)with two buttons labelled IN \n",
      "and OUT. If the user clicks the IN button, the message “DOCTOR IS IN” flashes and if the \n",
      "user click OUT button the message “DOCTOR IS OUT” flashes. \n",
      " (8 marks) \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(b) Bu use of examples, discuss the concept of method overloading and method overriding as used \n",
      "in object oriented programming. \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "(8 marks) \n",
      "(c) Explain the advantage for programming your GUI in an applet environment vs SWING \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "               (4 marks)  \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "QUESTION FIVE (20 MARKS) \n",
      "(a) Write a java program to create a class ‘STUDENT’ with data members Rgno, Name, Course, \n",
      "Branch, and Semester. Store them in an array of objects. \n",
      " \n",
      " \n",
      " \n",
      "(5 marks) \n",
      "(b) Write an applet that will display the resulting GUI below.  \n",
      " \n",
      " \n",
      "(15 marks) \n",
      "  \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\")\n",
    "    return text\n",
    "\n",
    "\n",
    "pdf_text = extract_text_from_pdf(\"C:/Users/Home/Desktop/LearningManagementAI/LearningManagementAI/Docs/past_paper.pdf\")\n",
    "print(pdf_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7189568-c48f-48ae-8e72-463a42548b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "engine.say(pdf_text)\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792874cf-ca19-4bf6-8b54-b72e93af7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def save_to_json(data, filename=\"study_data.json\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "# Example usage\n",
    "study_data = {\"topic\": \"Machine Learning\", \"content\": pdf_text}\n",
    "save_to_json(study_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d015ee9-5f2c-4be9-b718-567653ed70ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\W+\", \" \", text)\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words(\"english\")]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Example usage\n",
    "raw_text = \"Machine learning is a field of AI. Visit https://example.com for more!\"\n",
    "cleaned_text = clean_text(raw_text)\n",
    "print(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c48ab1-07fd-49b1-a5c0-78812a1e4513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "course_outline_text = extract_text_from_pdf(\"C:/Users/Home/Desktop/Comp3.1/Automata Theory303/COMP 303  AUTOMATA THEORY  COURSE OUTLINE.pdf\")\n",
    "print(course_outline_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5febd32b-7526-4817-ab34-0c552a3d62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "course_outline_text = extract_text_from_docx(\"C:/Users/Home/Desktop/Course Outline.docx\")\n",
    "print(course_outline_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a78cab-1886-4b28-a4c2-78dc089df521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import docx\n",
    "import pytesseract\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray)\n",
    "    return text\n",
    "\n",
    "def extract_course_info(text):\n",
    "    info = {\n",
    "        \"Course Title\": None,\n",
    "        \"Course Duration\": None,\n",
    "        \"Weekly Breakdown\": {},\n",
    "        \"Objectives\": [],\n",
    "        \"Recommended Materials\": []\n",
    "    }\n",
    "\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    course_title_pattern = re.compile(r\"(?i)Course\\s*Title:\\s*(.+)\")\n",
    "    duration_pattern = re.compile(r\"(?i)Duration:\\s*(.+)\")\n",
    "    week_pattern = re.compile(r\"(?i)Week\\s*(\\d+):?\\s*(.*)\")\n",
    "    objectives_pattern = re.compile(r\"(?i)Objectives?\")\n",
    "    materials_pattern = re.compile(r\"(?i)Recommended\\s*Materials?\")\n",
    "\n",
    "    current_section = None\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        title_match = course_title_pattern.search(line)\n",
    "        if title_match:\n",
    "            info[\"Course Title\"] = title_match.group(1)\n",
    "            continue\n",
    "\n",
    "        duration_match = duration_pattern.search(line)\n",
    "        if duration_match:\n",
    "            info[\"Course Duration\"] = duration_match.group(1)\n",
    "            continue\n",
    "\n",
    "        week_match = week_pattern.search(line)\n",
    "        if week_match:\n",
    "            week_number = int(week_match.group(1))\n",
    "            week_content = week_match.group(2).strip()\n",
    "            info[\"Weekly Breakdown\"][week_number] = week_content\n",
    "            continue\n",
    "\n",
    "        if objectives_pattern.search(line):\n",
    "            current_section = \"Objectives\"\n",
    "            continue\n",
    "        elif materials_pattern.search(line):\n",
    "            current_section = \"Recommended Materials\"\n",
    "            continue\n",
    "\n",
    "        if current_section == \"Objectives\":\n",
    "            info[\"Objectives\"].append(line)\n",
    "        elif current_section == \"Recommended Materials\":\n",
    "            info[\"Recommended Materials\"].append(line)\n",
    "\n",
    "    return info\n",
    "\n",
    "def process_course_outline(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use PDF or DOCX.\")\n",
    "\n",
    "    return extract_course_info(text)\n",
    "\n",
    "# Example Usage\n",
    "file_path = \"C:/Users/Home/Desktop/Comp 3.2/Comp 302/SOEN 302 - COMP 302 course outline.docx\" \n",
    "course_data = process_course_outline(file_path)\n",
    "\n",
    "print(course_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c7b4bb-00a6-4e55-9f0b-36e23594ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import docx\n",
    "import pytesseract\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    text = pytesseract.image_to_string(gray)\n",
    "    return text\n",
    "\n",
    "def extract_course_info(text):\n",
    "    info = {\n",
    "        \"Course Title\": None,\n",
    "        \"Course Code\": None,\n",
    "        \"Course Duration\": None,\n",
    "        \"Weekly Breakdown\": {},\n",
    "        \"Objectives\": [],\n",
    "        \"Recommended Materials\": []\n",
    "    }\n",
    "\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    course_title_pattern = re.compile(r\"(?i)([A-Z]{3,4}\\s*\\d{3})\\s*[-:]?\\s*(.+)\")\n",
    "    duration_pattern = re.compile(r\"(?i)Duration:\\s*(.+)\")\n",
    "\n",
    "    week_pattern = re.compile(r\"(?i)(?:Week\\s*|^)(\\d+)[\\.:]?\\s*(.*)\")\n",
    "    bullet_pattern = re.compile(r\"^[•*-]\\s*(.+)\")\n",
    "\n",
    "    objectives_pattern = re.compile(r\"(?i)Objectives?\")\n",
    "    materials_pattern = re.compile(r\"(?i)Recommended\\s*Materials?\")\n",
    "\n",
    "    current_section = None\n",
    "    week_counter = 0\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        title_match = course_title_pattern.search(line)\n",
    "        if title_match:\n",
    "            info[\"Course Code\"] = title_match.group(1)\n",
    "            info[\"Course Title\"] = title_match.group(2)\n",
    "            continue\n",
    "\n",
    "        duration_match = duration_pattern.search(line)\n",
    "        if duration_match:\n",
    "            info[\"Course Duration\"] = duration_match.group(1)\n",
    "            continue\n",
    "\n",
    "        week_match = week_pattern.search(line)\n",
    "        if week_match:\n",
    "            week_number = int(week_match.group(1))\n",
    "            week_content = week_match.group(2).strip()\n",
    "            info[\"Weekly Breakdown\"][week_number] = week_content\n",
    "            continue\n",
    "\n",
    "        bullet_match = bullet_pattern.search(line)\n",
    "        if bullet_match:\n",
    "            week_counter += 1\n",
    "            info[\"Weekly Breakdown\"][week_counter] = bullet_match.group(1)\n",
    "            continue\n",
    "\n",
    "        if objectives_pattern.search(line):\n",
    "            current_section = \"Objectives\"\n",
    "            continue\n",
    "        elif materials_pattern.search(line):\n",
    "            current_section = \"Recommended Materials\"\n",
    "            continue\n",
    "\n",
    "        if current_section == \"Objectives\":\n",
    "            info[\"Objectives\"].append(line)\n",
    "        elif current_section == \"Recommended Materials\":\n",
    "            info[\"Recommended Materials\"].append(line)\n",
    "\n",
    "    return info\n",
    "\n",
    "def process_course_outline(file_path):\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use PDF or DOCX.\")\n",
    "\n",
    "    return extract_course_info(text)\n",
    "\n",
    "file_path = \"C:/Users/Home/Desktop/Comp 3.2/Comp 306/COMP 306 CO.pdf\" \n",
    "course_data = process_course_outline(file_path)\n",
    "\n",
    "print(course_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d34a17-e7cd-4872-be4a-0c3327bd14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_weeks_and_topics(text):\n",
    "    weeks = re.findall(r\"Week \\d+: (.+)\", text)\n",
    "    return weeks\n",
    "\n",
    "weekly_topics = extract_weeks_and_topics(course_outline_text)\n",
    "print(weekly_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68ecff-9e61-4b84-9f77-011e24d0ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "from serpapi import GoogleSearch\n",
    "\n",
    "def scrape_study_materials(topic):\n",
    "    api_key = \"4c3a39f406bb56f40ea28e7b2b59186206d9eb054c352ef8e19552d9900611f2\"\n",
    "    search = GoogleSearch({\n",
    "        \"q\": f\"{topic} study materials\",\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"us\",\n",
    "        \"api_key\": api_key\n",
    "    })\n",
    "    \n",
    "    results = search.get_dict()\n",
    "    links = []\n",
    "\n",
    "    for result in results.get(\"organic_results\", []):\n",
    "        if \"link\" in result:\n",
    "            links.append(result[\"link\"])\n",
    "    \n",
    "    return links[:5]\n",
    "\n",
    "def summarize_article(url):\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "        return article.summary\n",
    "    except Exception as e:\n",
    "        return f\"Error processing article: {e}\"\n",
    "\n",
    "study_materials = scrape_study_materials(\"Machine Learning\")\n",
    "\n",
    "if study_materials:\n",
    "    summary = summarize_article(study_materials[0])\n",
    "    print(\"Summary of the first article:\\n\", summary)\n",
    "else:\n",
    "    print(\"No study materials found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf5053-65af-4c05-a820-00539224f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff117cc5-6092-4197-81c5-01f4470d668b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88cfba0-a799-4464-886f-f5452ad80771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b74d4-81b6-4095-ad87-4e752a1097da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950d4cf-e579-41af-a14e-a0d681ddc735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
